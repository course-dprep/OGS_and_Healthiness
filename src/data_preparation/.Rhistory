new = c("date", "units", "value", "volume", "panelist", "barcode", "retailer", "brand",
"measurement_unit", "segment", "channel"))
# create structure in columns for overview
setcolorder(DT, c("panelist", "date", "retailer", "barcode", "brand", "segment", "channel", "units", "value", "volume", "measurement_unit") )
# identifying online shoppers
# week_number variable
start_date <- as.Date("2019-01-01") # observation begins on tuesday 01-01-2019
start_date <- start_date - (wday(start_date) - 2) # start week 1 on a Monday
DT <- DT[, week_number := as.integer(difftime(date, start_date, units = "weeks") + 1)]
# identify online shoppers (at least online once)
DT[, number_online_trips := uniqueN(date[channel == "online"]), by = panelist]
DT[, shopper_type := fifelse(number_online_trips == 0, 0, 1), by = panelist]
DT[, first_purchase_week := min(week_number), by = panelist]
DT[, last_purchase_week := max(week_number), by = panelist]
# error in data.table so continue with dplyr
DT <- DT %>% group_by(panelist) %>%
mutate(first_online_week = ifelse(shopper_type ==1, min(week_number[channel == "online"]), 0))
# filter at least 4 weeks of data before & after online adoption moment
adopters <- DT %>% filter(shopper_type == 1)
adopters <- adopters %>%
group_by(panelist) %>%
mutate(
weeks_before_adoption = first_online_week - first_purchase_week,
weeks_after_adoption = last_purchase_week - first_online_week + 1) %>%
ungroup()
adopters <- adopters %>% filter(weeks_before_adoption >= 4 & weeks_after_adoption >= 4)
#filter online shoppers in DT
DT <- DT %>% filter(panelist %in% adopters$panelist | shopper_type == 0)
# aggregation purchase level
weekly_baskets <- setDT(DT %>% group_by(panelist, week_number) %>%
summarise(
treatment_group = first(shopper_type),
cohort_period = first(first_online_week),
prop_expenditure_vegetables_fruits = (sum(value[segment == "groente"]) + sum(value[segment == "fruit"]))  / sum(value) * 100) %>%
ungroup() )
# saving prepared dataset
setwd("~/online-groceries-impact-healthiness")
fwrite(weekly_baskets, "~/online-groceries-impact-healthiness/gen/data_preparation/weekly_baskets.csv")
# saving prepared dataset
setwd("~")
fwrite(weekly_baskets, "~/online-groceries-impact-healthiness/gen/data_preparation/weekly_baskets.csv")
fwrite(weekly_baskets, "online-groceries-impact-healthiness/gen/data_preparation/weekly_baskets.csv")
fwrite(weekly_baskets, "./online-groceries-impact-healthiness/gen/data_preparation/weekly_baskets.csv")
getwd()
fwrite(weekly_baskets, "~/online-groceries-impact-healthiness/gen/data-preparation/weekly_baskets.csv")
library(dplyr)
# Sample data
data <- tibble(
group = c("A", "A", "B", "B", "C", "C", "C"),
value1 = c(5, 3, 8, 4, 7, 6, 2),
value2 = c(1, 4, 3, 6, 5, 2, 9)
)
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2 / mean_value1  # Error is hidden here
) %>%
filter(mean_value1 > 4) %>%
arrange(desc(ratio))
View(result)
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2 / mean_value) %>%
filter(mean_value1 > 4) %>%
arrange(desc(ratio))
rm(list = ls())
# Sample data
data <- tibble(
group = c("A", "A", "B", "B", "C", "C", "C"),
value1 = c(5, 3, 8, 4, 7, 6, 2),
value2 = c(1, 4, 3, 6, 5, 2, 9)
)
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2 / mean_value) %>%
filter(mean_value1 > 4) %>%
arrange(desc(ratio))
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2 / mean_value1) %>%
filter(mean_value1 > 4) %>%
arrange(desc(ratio))
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2  mean_value1) %>%
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2 / mean_value1) %>%
filter(mean_value1 > 4) %>%
arrange(desc(ratio))
print(result)
rm(list= ls())
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2 / mean_value1) %>%
filter(mean_value1 > 4) %>%
arrange(desc(ratio))
# Sample data
data <- tibble(
group = c("A", "A", "B", "B", "C", "C", "C"),
value1 = c(5, 3, 8, 4, 7, 6, 2),
value2 = c(1, 4, 3, 6, 5, 2, 9)
)
# Complex dplyr code
result <- data %>%
group_by(group) %>%
summarise(
mean_value1 = mean(value1),
total_value2 = sum(value2),
ratio = total_value2 / mean_value1) %>%
filter(mean_value1 > 4) %>%
arrange(desc(ratio))
rm(list = ls())
library(dplyr)
library(tidyr)
# Sample data: Product sales and Customer info
sales_data <- tibble(
customer_id = c(101, 102, 103, 101, 104, 105, 106, 107),
product_id = c(1, 1, 2, 3, 3, 2, 2, 1),
sales_amount = c(200, 150, 300, 400, 250, 350, 150, 100),
sales_date = as.Date(c('2023-01-01', '2023-02-01', '2023-02-10',
'2023-03-15', '2023-04-10', '2023-04-15',
'2023-05-01', '2023-06-01'))
)
customer_info <- tibble(
customer_id = c(101, 102, 103, 104, 105, 106, 107),
customer_name = c("Alice", "Bob", "Charlie", "David", "Eve", "Frank", "Grace"),
signup_date = as.Date(c('2022-12-15', '2022-12-25', '2023-01-10',
'2023-02-05', '2023-03-01', '2023-03-15',
'2023-04-01'))
)
# Complex dplyr operations
result <- sales_data %>%
filter(sales_date >= as.Date('2023-01-01')) %>%  # Keep sales from 2023 onwards
group_by(customer_id, product_id) %>%
summarise(
total_sales = sum(sales_amount),
avg_sales_per_transaction = mean(sales_amount),
sales_count = n(),
.groups = 'drop'
) %>%
filter(sales_count > 1) %>%  # Keep only customers who purchased more than once
left_join(customer_info, by = "customer_id") %>%
mutate(
time_since_signup = as.numeric(difftime(sales_date, signup_date, units = "days"))
) %>%
filter(time_since_signup >= 0) %>%  # Keep transactions that occurred after sign-up
arrange(desc(total_sales))
# Complex dplyr operations
result <- sales_data %>%
filter(sales_date >= as.Date('2023-01-01')) %>%
group_by(customer_id, product_id) %>%
summarise(
total_sales = sum(sales_amount),
avg_sales_per_transaction = mean(sales_amount),
sales_count = n()) %>%
left_join(customer_info, by = "customer_id") %>%
mutate(
time_since_signup = as.numeric(difftime(sales_date, signup_date, units = "days"))) %>%
filter(time_since_signup >= 0)
result <- sales_data %>%
filter(sales_date >= as.Date('2023-01-01')) %>%
group_by(customer_id, product_id) %>%
summarise(
total_sales = sum(sales_amount),
avg_sales_per_transaction = mean(sales_amount),
sales_count = n()) %>%
left_join(customer_info, by = "customer_id") %>%
mutate(
time_since_signup = as.numeric(difftime(sales_date, units = "days"))) %>%
filter(time_since_signup >= 0)
rm(list=ls())
rooms <- c(1,2,1,8)
max(rooms)
rooms <- c(, NA)
rooms <- c(1,2,1,8,NA)
max(rooms)
max(rooms, na.rm = TRUE)
rooms[3]
rooms(rooms > 2)
rooms[>2]
rooms[rooms >2]
rooms[rooms >= 2, na.rm = TRUE]
rooms[rooms >= 2]
download.file("https://raw.githubusercontent.com/hannesdatta/course-dprep/master/content/docs/modules/week4/regional-global-daily-latest.csv", "streams.csv")
library(tidyverse)
streams <- read_csv('streams.csv', skip=1)
streams %>% select(`Track Name`)
View(streams %>% select(`Track Name`))
streams %>% group_by(Artist) %>% summarize(total_streams = sum(Streams)) %>% arrange(desc(total_streams))
View(streams %>% group_by(Artist) %>% summarize(total_streams = sum(Streams)) %>% arrange(desc(total_streams)))
l
datasets <- lapply(urls, read_delim, delim='\t', na = '\\N')
urls = c('https://datasets.imdbws.com/title.episode.tsv.gz', 'https://datasets.imdbws.com/title.ratings.tsv.gz')
datasets <- lapply(urls, read_delim, delim='\t', na = '\\N')
lapply(summary(datasets))
lapply(datasets, summary)
View(streams)
cols_to_drop <- c("Artist", "URL")
datasets %>% remove(cols_to_drop)
View(streams)
streams %>% remove(cols_to_drop)
streams <- streams %>% select(-cols_to_drop)
View(streams)
help(ignore.case)
??ignore.case
View(streams)
df = streams %>% top_n(10, Streams)
View(df)
df <- streams %>% top_n(10, Streams)
streams <- streams %>% filter(-cols_to_drop)
streams <- streams %>% select(-cols_to_drop)
streams <- read_csv('streams.csv', skip=1)
streams <- streams %>% filter(-cols_to_drop)
View(streams)
streams <- streams %>% filter(-cols_to_drop)
streams <- streams %>% select(-cols_to_drop)
le <- c("pop", "canadian pop", "post-teen pop", "viral pop", "dance pop")
genres_examp
genres_example <- c("pop", "canadian pop", "post-teen pop", "viral pop", "dance pop")
genres_example_split <- split(genres_example, ",")
genres_example_split[[1]]
??pivot_wider()
download.file('https://gist.githubusercontent.com/hannesdatta/1f764090ae3ebfaabe7a91ea4b971c3d/raw/2df12443cd144141dedb866967cbe985b97052f5/run_antwerp.R', 'run_antwerp.R')
getwd()
getwd()
setwd("C:/Users/kleingol/Desktop/Courses/Dataprep/exam test")
install.packages('svglite_2.1.3.tar', repos=NULL,  type='source')
# Exam test questions
rm(list=ls())
# load packages
library(data.table)
library(dplyr)
# open data
purchases_2019 <- fread("../../gen/data_preparation/input/data_clean.csv")
# open data
purchases_2019 <- fread("../../gen/data_preparation/input/data_clean.csv")
getwd()
setwd("~/online-groceries-impact-healthiness/src/data_preparation")
getwd()
# open data
purchases_2019 <- fread("../../gen/data_preparation/input/data_clean.csv")
# weekly basket aggregation
weekly_baskets_2019 <- setDT(purchases_2019 %>% group_by(panelist, week_number) %>%
summarise(
treatment_group = first(shopper_type),
cohort_period = first(first_online_week),
prop_expenditure_vegetables = sum(value[segment == c("groente", "fruit")]) / sum(value) * 100) %>%
ungroup() )
View(purchases_2019)
table(purchases_2019$segment)
# weekly basket aggregation
weekly_baskets_2019 <- setDT(purchases_2019 %>% group_by(panelist, week_number) %>%
summarise(
treatment_group = first(shopper_type),
cohort_period = first(first_online_week),
prop_expenditure_vegetables = sum(value[segment %in% c("groente", "fruit")])) / sum(value) * 100) %>%
ungroup() )
# weekly basket aggregation
weekly_baskets_2019 <- setDT(purchases_2019 %>% group_by(panelist, week_number) %>%
summarise(
treatment_group = first(shopper_type),
cohort_period = first(first_online_week),
prop_expenditure_vegetables = sum(value[segment %in% c("groente", "fruit")]) / sum(value) * 100) %>%
ungroup() )
rm(weekly_baskets_2019)
# weekly basket aggregation
weekly_baskets_2019 <- setDT(purchases_2019 %>% group_by(panelist, week_number) %>%
summarise(
treatment_group = first(shopper_type),
cohort_period = first(first_online_week),
prop_expenditure_vegetables = sum(value[segment %in% c("groente", "fruit")]) / sum(value) * 100) %>%
ungroup() )
View(weekly_baskets_2019)
# weekly basket aggregation
weekly_baskets_2019 <- setDT(purchases_2019 %>% group_by(panelist, week_number) %>%
summarise(
treatment_group = first(shopper_type),
cohort_period = first(first_online_week),
prop_expenditure_fruit_vegetables = sum(value[segment %in% c("groente", "fruit")]) / sum(value) * 100) %>%
ungroup() )
fwrite(weekly_baskets_2019, "../../gen/data_preparation/input/weekly_baskets_2019.csv")
rm(list=ls())
library(data.table)
library(did)
weekly_baskets_2019 <- fread("../../gen/data_preparation/input/weekly_baskets_2019.csv")
dir.create("../../gen/analysis/")
View(weekly_baskets_2019)
table(weekly_baskets_2019$cohort_period)
# method required a treated indicator
weekly_baskets_2019[, treated := ifelse(treatment_group == 1 & week_number >= cohort_period, 1, 0)]
weekly_baskets_2019[, panelist_numeric := as.numeric(factor(weekly_baskets$panelist, levels = unique(weekly_baskets$panelist)))]
weekly_baskets_2019[, panelist_numeric := as.numeric(factor(weekly_baskets_2019$panelist, levels = unique(weekly_baskets_2019$panelist)))]
View(weekly_baskets_2019)
did_model <- att_gt(yname = "prop_expenditure_fruit_vegetables",
tname = "week_number",
idname = "panelist_numeric",
gname = "cohort_period",
control_group = "nevertreated",
xformla = ~1,
data = weekly_baskets_2019,
allow_unbalanced_panel = TRUE,
clustervars = "panelist")
# model results table
summary(did_model)
#52 week time window around adoption
cs_rel_period_effects <- aggte(
cs_did,
type = "dynamic",
min_e = -8,  max_e = 8, na.rm = TRUE)
#52 week time window around adoption
cs_rel_period_effects <- aggte(
did_model,
type = "dynamic",
min_e = -8,  max_e = 8, na.rm = TRUE)
plot <- ggdid(cs_rel_period_effects)
plot + scale_x_continuous(breaks = seq(from = min(cs_rel_period_effects$egt),
to = max(cs_rel_period_effects$egt),
by = 4))
# average results of model
average_did_effect  <- aggte(did_model, type = "simple", na.rm = TRUE)
View(average_did_effect)
summary(average_did_effect)
# confidence interval 8-week time window around online adoption
cs_rel_period_effects <- aggte(
did_model,
type = "dynamic",
min_e = -8,  max_e = 8, na.rm = TRUE)
# confidence interval 8-week time window around online adoption
time_window_effects <- aggte(
did_model,
type = "dynamic",
min_e = -8,  max_e = 8, na.rm = TRUE)
ggdid(cs_group_effects)
cs_group_effects <- aggte(cs_did, type = "group", na.rm = TRUE)
cs_group_effects <- aggte(did_model, type = "group", na.rm = TRUE)
ggdid(cs_group_effects)
# effects per cohort
cohort_effects <- aggte(did_model, type = "group", na.rm = TRUE)
ggdid(cohort_effects)
summary(average_did_effect)
time_window_plot <- ggdid(cs_rel_period_effects)
time_window_plot <- ggdid(time_window_effects)
time_window_plot + scale_x_continuous(breaks = seq(from = min(cs_rel_period_effects$egt),
to = max(cs_rel_period_effects$egt),
by = 4))
time_window_plot <- ggdid(time_window_effects)
ggdid(time_window_effects) +
ggdid(time_window_effects) +
scale_x_continuous(breaks = seq(from = min(time_window_effects$egt),
to = max(time_window_effects$egt),
by = 4))
time_window_plot <- ggdid(time_window_effects) +
scale_x_continuous(breaks = seq(from = min(time_window_effects$egt),
to = max(time_window_effects$egt),
by = 4))
time_window_plot <- ggdid(time_window_effects) +
scale_x_continuous(breaks = seq(from = min(time_window_effects$egt),
to = max(time_window_effects$egt),
by = 4))
rm(list=ls())
# directory creation for analysis output
dir.create("../../gen/analysis/")
# load in dataset
weekly_baskets_2019 <- fread("../../gen/data_preparation/input/weekly_baskets_2019.csv")
# method required a treated indicator
weekly_baskets_2019[, treated := ifelse(treatment_group == 1 & week_number >= cohort_period, 1, 0)]
weekly_baskets_2019[, panelist_numeric := as.numeric(factor(weekly_baskets_2019$panelist, levels = unique(weekly_baskets_2019$panelist)))]
# run did model
did_model <- att_gt(yname = "prop_expenditure_fruit_vegetables",
tname = "week_number",
idname = "panelist_numeric",
gname = "cohort_period",
control_group = "nevertreated",
xformla = ~1,
data = weekly_baskets_2019,
allow_unbalanced_panel = TRUE,
clustervars = "panelist")
# average results of model
average_did_effect  <- aggte(did_model, type = "simple", na.rm = TRUE)
summary(average_did_effect)
summary(average_did_effect)
# Print summary of average effects to a text file
sink(paste0("../../gen/analysis/", "average_did_effect_summary.txt"))
print(summary(average_did_effect))
sink()
# Print summary of average effects to a text file
sink(paste0("../../gen/analysis/", "average_did_effect_summary.txt"))
print(summary(average_did_effect))
sink()
# Print summary of average effects to a text file
sink(paste0("../../gen/analysis/", "average_did_effect_summary.txt"))
print(summary(average_did_effect))
sink()
ggdid(cohort_effects)
# effects per cohort
cohort_effects <- aggte(did_model, type = "group", na.rm = TRUE)
ggdid(cohort_effects)
# setup PDF for output plots and tables
pdf(file = paste0("../../gen/analysis/", "did_effect_plots.pdf"))
# setup PDF for output plots and tables
pdf(file = paste0("../../gen/analysis/", "analysis_results.pdf"))
# creating analysis output pdf
grid.table(summary(average_did_effect))
library(gridExtra)
# creating analysis output pdf
grid.table(summary(average_did_effect))
ggdid(time_window_effects) +
scale_x_continuous(breaks = seq(from = min(time_window_effects$egt),
to = max(time_window_effects$egt),
by = 4)) |>
print()
# confidence interval 8-week time window around online adoption
time_window_effects <- aggte(
did_model,
type = "dynamic",
min_e = -8,  max_e = 8, na.rm = TRUE)
ggdid(time_window_effects) +
scale_x_continuous(breaks = seq(from = min(time_window_effects$egt),
to = max(time_window_effects$egt),
by = 4)) |>
print()
# Print the summary of cohort effects directly into the PDF
grid.table(summary(cohort_effects))
# Plot cohort effects and save to the PDF
ggdid(cohort_effects) |> print()
dev.off()
# setup PDF for output plots and tables
pdf(file = paste0("../../gen/analysis/", "analysis_results.pdf"))
rm(list=ls())
# directory creation for analysis output
dir.create("../../gen/analysis/")
# setup PDF for output plots and tables
pdf(file = paste0("../../gen/analysis/", "analysis_results.pdf"))
# load in dataset
weekly_baskets_2019 <- fread("../../gen/data_preparation/input/weekly_baskets_2019.csv")
# method required a treated indicator
weekly_baskets_2019[, treated := ifelse(treatment_group == 1 & week_number >= cohort_period, 1, 0)]
weekly_baskets_2019[, panelist_numeric := as.numeric(factor(weekly_baskets_2019$panelist, levels = unique(weekly_baskets_2019$panelist)))]
# run did model
did_model <- att_gt(yname = "prop_expenditure_fruit_vegetables",
tname = "week_number",
idname = "panelist_numeric",
gname = "cohort_period",
control_group = "nevertreated",
xformla = ~1,
data = weekly_baskets_2019,
allow_unbalanced_panel = TRUE,
clustervars = "panelist")
# average results of model
average_did_effect  <- aggte(did_model, type = "simple", na.rm = TRUE)
# confidence interval 8-week time window around online adoption
time_window_effects <- aggte(
did_model,
type = "dynamic",
min_e = -8,  max_e = 8, na.rm = TRUE)
# effects per cohort
cohort_effects <- aggte(did_model, type = "group", na.rm = TRUE)
ggdid(cohort_effects)
# creating analysis output pdf
grid.table(summary(average_did_effect))
dev.off()
# average results of model
average_did_effect  <- aggte(did_model, type = "simple", na.rm = TRUE)
# confidence interval 8-week time window around online adoption
time_window_effects <- aggte(
did_model,
type = "dynamic",
min_e = -8,  max_e = 8, na.rm = TRUE)
# effects per cohort
cohort_effects <- aggte(did_model, type = "group", na.rm = TRUE)
ggdid(cohort_effects)
# creating analysis output pdf
grid.table(summary(average_did_effect))
ggdid(time_window_effects) +
scale_x_continuous(breaks = seq(from = min(time_window_effects$egt),
to = max(time_window_effects$egt),
by = 4)) |>
print()
# Print the summary of cohort effects directly into the PDF
grid.table(summary(cohort_effects))
# Plot cohort effects and save to the PDF
ggdid(cohort_effects) |> print()
dev.off()
getwd()
